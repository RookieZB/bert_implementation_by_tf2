{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"task_cls.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"toQJl6Q4xjDp","colab_type":"text"},"source":["A classification example for BERT using Google Colab.  \n","The data is from https://github.com/FudanNLP/nlpcc2017_news_headline_categorization.\n"]},{"cell_type":"code","metadata":{"id":"lcqMY1loYEYm","colab_type":"code","colab":{}},"source":["!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n","!mkdir -p drive\n","!google-drive-ocamlfuse drive"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rBlT22miZU8c","colab_type":"code","colab":{}},"source":["import os\n","import warnings\n","os.chdir('drive/python/project01/bert')\n","warnings.filterwarnings('ignore')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9TsxfYM1NkM2","colab_type":"code","colab":{}},"source":["try:\n","  %tensorflow_version 2.x\n","except Exception:\n","  pass\n","\n","import time\n","import json\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import tensorflow.keras as keras\n","from sklearn import preprocessing\n","from bert_by_tf2 import BERT, DecayingADAM, Tokenizer"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ik9wS_1LPBlC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":252},"outputId":"fecb3af8-5bae-4cdc-d478-db83b2103426","executionInfo":{"status":"ok","timestamp":1582454597175,"user_tz":-480,"elapsed":10694,"user":{"displayName":"Chris Chen","photoUrl":"","userId":"15295307384944031263"}}},"source":["trai_1 = pd.read_table('datasets/a/train.txt', header=None, names=['label', 'text'])\n","deve_1 = pd.read_table('datasets/a/dev.txt', header=None, names=['label', 'text'])\n","test_1 = pd.read_table('datasets/a/test.txt', header=None, names=['label', 'text'])\n","print(test_1)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["               label                                            text\n","0               baby                 生完 小孩 ， 公公 伺候 我 坐月子 ， 很 羞涩 很 感动\n","1            fashion    唐艺昕 与 陈伟霆 为 初秋 的 情侣 做出 了 典范 ， 看 他们 如何 穿 情侣 衣\n","2      entertainment  同学聚会 美女 被 嘲笑 是 剩女 ， 当超帅 老公 带 着 儿子 出场 ， 全场 沸腾 了\n","3            finance                             中国 供给 侧 至少 存在 六大 问题\n","4              world                                2.5 万英镑 可住 戴妃 闺房\n","...              ...                                             ...\n","35969         travel               白俄罗斯 小镇 美女 愁 嫁 ， 年轻 姑娘 都 想 嫁 到 中国\n","35970          world                 香港市民 游行 抗议 安倍 企图 修宪吁 警惕 军国主义 复辟\n","35971        finance                                 网贷 诈骗 平台 的 狐狸尾巴\n","35972         sports                 巅峰 雷阿伦 单挑 如今 的 库里 ， 谁 的 赢面 更大 ？\n","35973        society               “ 学生家长 ” 到 培训班 咨询 顺走 老师 现金 、 手机 ？\n","\n","[35974 rows x 2 columns]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mT-9Ky25bay2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":319},"outputId":"0a42fdcb-958f-41c2-ed09-53a81254200a","executionInfo":{"status":"ok","timestamp":1582454600653,"user_tz":-480,"elapsed":1017,"user":{"displayName":"Chris Chen","photoUrl":"","userId":"15295307384944031263"}}},"source":["labe_1 = preprocessing.LabelEncoder()\n","trai_1['label'] = labe_1.fit_transform(trai_1['label'])\n","deve_1['label'] = labe_1.transform(deve_1['label'])\n","test_1['label'] = labe_1.transform(test_1['label'])\n","\n","for i in range(18):\n","    print(i, labe_1.inverse_transform([i])[0])"],"execution_count":5,"outputs":[{"output_type":"stream","text":["0 baby\n","1 car\n","2 discovery\n","3 entertainment\n","4 essay\n","5 fashion\n","6 finance\n","7 food\n","8 game\n","9 history\n","10 military\n","11 regimen\n","12 society\n","13 sports\n","14 story\n","15 tech\n","16 travel\n","17 world\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4B2HpNZ7b9N7","colab_type":"code","colab":{}},"source":["MAXLEN = 40\n","CATE = 18\n","DROP = 0.5\n","DIM = 128\n","LRATE = 5e-5\n","BATCH = 64\n","EPOCH = 3"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cXuiXbNfYCuY","colab_type":"code","colab":{}},"source":["def data_processing(data, tokenizer, maxlen, batch):\n","    text1, type1, mask1, labe1 = [], [], [], []\n","\n","    for i in range(len(data)):\n","        text2, type2, mask2 = tokenizer.encoding(data['text'][i], None, maxlen)\n","        labe2 = data['label'][i]\n","        text1.append(text2)\n","        type1.append(type2)\n","        mask1.append(mask2)\n","        labe1.append(labe2)\n","\n","    text1, type1, mask1, labe1 = np.array(text1), np.array(type1), np.array(mask1), np.array(labe1)\n","    return tf.data.Dataset.from_tensor_slices((text1, type1, mask1, labe1)).shuffle(len(text1)).batch(batch)\n","\n","toke_1 = Tokenizer()\n","toke_1.loading('bert/models/bert_base_ch/vocab.txt')\n","trai_2 = data_processing(trai_1, toke_1, MAXLEN, BATCH)\n","deve_2 = data_processing(deve_1, toke_1, MAXLEN, BATCH)\n","test_2 = data_processing(test_1, toke_1, MAXLEN, BATCH)\n","step_1 = EPOCH*(int(len(trai_1)/BATCH)+1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gzXMCDSad3rV","colab_type":"code","colab":{}},"source":["class MyModel(keras.Model):\n","  def __init__(self, config, drop, dim, category):\n","    super(MyModel, self).__init__()\n","    self.bert = BERT(config)\n","    self.drop = keras.layers.Dropout(drop)\n","    self.dense1 = keras.layers.Dense(dim, activation='relu')\n","    self.dense2 = keras.layers.Dense(category, activation='softmax')\n","\n","  def propagating(self, text, segment, mask, training):\n","    x1 = self.bert.propagating(text, segment, mask, True, training)\n","    x1 = self.drop(x1, training=training)\n","    return self.dense2(self.dense1(x1))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QRai4oFr-qtx","colab_type":"code","colab":{}},"source":["loss_1 = keras.losses.SparseCategoricalCrossentropy()\n","opti_1 = DecayingADAM(step_1, LRATE)\n","mode_1 = MyModel('bert/models/bert_base_ch/bert_config.json', DROP, DIM, CATE)\n","mode_1.bert.loading('bert/models/bert_base_ch/bert_model.ckpt')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RxHmRINF9R2x","colab_type":"code","colab":{}},"source":["l_1 = tf.keras.metrics.Mean(name='training_loss')\n","a_1 = tf.keras.metrics.SparseCategoricalAccuracy(name='training_accuracy')\n","l_2 = tf.keras.metrics.Mean(name='test_loss')\n","a_2 = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n","coun_1 = 0\n","\n","@tf.function\n","def step_training(text, segment, mask, y):\n","  with tf.GradientTape() as tape:\n","    pred1 = mode_1.propagating(text, segment, mask, True)\n","    loss1 = loss_1(y, pred1)\n","\n","  grad_1 = tape.gradient(loss1, mode_1.trainable_variables)\n","  opti_1.apply_gradients(zip(grad_1, mode_1.trainable_variables))\n","  l_1(loss1)\n","  a_1(y, pred1)\n","\n","@tf.function\n","def step_evaluating(text, segment, mask, y):\n","  pred1 = mode_1.propagating(text, segment, mask, False)\n","  loss1 = loss_1(y, pred1)\n","  l_2(loss1)\n","  a_2(y, pred1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pFLOn6g1--aM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"657553b4-4103-4e31-b585-bf7c54749f0b","executionInfo":{"status":"ok","timestamp":1582460041759,"user_tz":-480,"elapsed":2422315,"user":{"displayName":"Chris Chen","photoUrl":"","userId":"15295307384944031263"}}},"source":["temp_1 = 'Epoch {} running, training loss is {}, and training accuracy is {}, and step cost is {}.'\n","temp_2 = 'Epoch {} completed, training loss is {}, training accuracy is {}, test loss is {}, and test accuracy is {}.'\n","\n","for e_1 in range(EPOCH):\n","  for x_1, x_2, x_3, y_1 in trai_2:\n","    time_1 = time.time()\n","    step_training(x_1, x_2, x_3, y_1)\n","    coun_1 = coun_1+1\n","\n","    if coun_1 % 100 == 0:\n","        print(temp_1.format(e_1+1, l_1.result(), a_1.result(), time.time()-time_1))\n","\n","  for x_1, x_2, x_3, y_1 in deve_2:\n","    step_evaluating(x_1, x_2, x_3, y_1)\n","\n","  print(temp_2.format(e_1+1, l_1.result(), a_1.result(), l_2.result(), a_2.result()))\n","  print('**********')"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Epoch 1 running, training loss is 2.32075572013855, and training accuracy is 0.34312498569488525, and step cost is 0.6965832710266113.\n","Epoch 1 running, training loss is 1.6398135423660278, and training accuracy is 0.5415624976158142, and step cost is 0.7103571891784668.\n","Epoch 1 running, training loss is 1.3880748748779297, and training accuracy is 0.6152083277702332, and step cost is 0.7120764255523682.\n","Epoch 1 running, training loss is 1.249719500541687, and training accuracy is 0.6538671851158142, and step cost is 0.674846887588501.\n","Epoch 1 running, training loss is 1.165598750114441, and training accuracy is 0.6775312423706055, and step cost is 0.6955010890960693.\n","Epoch 1 running, training loss is 1.1035981178283691, and training accuracy is 0.6946094036102295, and step cost is 0.6796801090240479.\n","Epoch 1 running, training loss is 1.0543708801269531, and training accuracy is 0.7075892686843872, and step cost is 0.709733247756958.\n","Epoch 1 running, training loss is 1.021166205406189, and training accuracy is 0.7161914110183716, and step cost is 0.6880004405975342.\n","Epoch 1 running, training loss is 0.9898396134376526, and training accuracy is 0.7240625023841858, and step cost is 0.6757535934448242.\n","Epoch 1 running, training loss is 0.9646620154380798, and training accuracy is 0.7307500243186951, and step cost is 0.7112047672271729.\n","Epoch 1 running, training loss is 0.9443170428276062, and training accuracy is 0.7358380556106567, and step cost is 0.6686398983001709.\n","Epoch 1 running, training loss is 0.9238570332527161, and training accuracy is 0.7408333420753479, and step cost is 0.7087297439575195.\n","Epoch 1 running, training loss is 0.9053519368171692, and training accuracy is 0.745516836643219, and step cost is 0.671088457107544.\n","Epoch 1 running, training loss is 0.8898674845695496, and training accuracy is 0.7495647072792053, and step cost is 0.6724264621734619.\n","Epoch 1 running, training loss is 0.8735109567642212, and training accuracy is 0.753989577293396, and step cost is 0.7184076309204102.\n","Epoch 1 running, training loss is 0.8615840077400208, and training accuracy is 0.7566211223602295, and step cost is 0.6990766525268555.\n","Epoch 1 running, training loss is 0.8497017621994019, and training accuracy is 0.759549617767334, and step cost is 0.7044446468353271.\n","Epoch 1 running, training loss is 0.8373834490776062, and training accuracy is 0.7628124952316284, and step cost is 0.6904549598693848.\n","Epoch 1 running, training loss is 0.827000081539154, and training accuracy is 0.7652137875556946, and step cost is 0.7094953060150146.\n","Epoch 1 running, training loss is 0.8174647688865662, and training accuracy is 0.7674687504768372, and step cost is 0.7017261981964111.\n","Epoch 1 running, training loss is 0.8098950386047363, and training accuracy is 0.7695833444595337, and step cost is 0.6987922191619873.\n","Epoch 1 running, training loss is 0.8008330464363098, and training accuracy is 0.7717045545578003, and step cost is 0.7255127429962158.\n","Epoch 1 running, training loss is 0.7938312292098999, and training accuracy is 0.7733423709869385, and step cost is 0.7032022476196289.\n","Epoch 1 running, training loss is 0.7863160371780396, and training accuracy is 0.775305986404419, and step cost is 0.7133023738861084.\n","Epoch 1 completed, training loss is 0.783954381942749, training accuracy is 0.775812566280365, test loss is 0.5779252052307129, and test accuracy is 0.8275941014289856.\n","**********\n","Epoch 2 running, training loss is 0.7750799059867859, and training accuracy is 0.7782125473022461, and step cost is 0.6911025047302246.\n","Epoch 2 running, training loss is 0.7635671496391296, and training accuracy is 0.7814605236053467, and step cost is 0.6962971687316895.\n","Epoch 2 running, training loss is 0.7535023093223572, and training accuracy is 0.7842769622802734, and step cost is 0.6952826976776123.\n","Epoch 2 running, training loss is 0.7430056929588318, and training accuracy is 0.7870819568634033, and step cost is 0.6780481338500977.\n","Epoch 2 running, training loss is 0.7337797284126282, and training accuracy is 0.7895371913909912, and step cost is 0.6989190578460693.\n","Epoch 2 running, training loss is 0.7248704433441162, and training accuracy is 0.7919589877128601, and step cost is 0.7058873176574707.\n","Epoch 2 running, training loss is 0.7160236835479736, and training accuracy is 0.794320285320282, and step cost is 0.6745908260345459.\n","Epoch 2 running, training loss is 0.7079195380210876, and training accuracy is 0.7964461445808411, and step cost is 0.6664121150970459.\n","Epoch 2 running, training loss is 0.7000517249107361, and training accuracy is 0.7985330820083618, and step cost is 0.6853249073028564.\n","Epoch 2 running, training loss is 0.6933014988899231, and training accuracy is 0.8003042340278625, and step cost is 0.6998894214630127.\n","Epoch 2 running, training loss is 0.6859669089317322, and training accuracy is 0.8022688627243042, and step cost is 0.6862883567810059.\n","Epoch 2 running, training loss is 0.6794253587722778, and training accuracy is 0.8040071129798889, and step cost is 0.6911952495574951.\n","Epoch 2 running, training loss is 0.6739996671676636, and training accuracy is 0.805516242980957, and step cost is 0.709118127822876.\n","Epoch 2 running, training loss is 0.6679506301879883, and training accuracy is 0.8071926832199097, and step cost is 0.7110087871551514.\n","Epoch 2 running, training loss is 0.6626478433609009, and training accuracy is 0.8085948824882507, and step cost is 0.7105836868286133.\n","Epoch 2 running, training loss is 0.6578879952430725, and training accuracy is 0.8098956346511841, and step cost is 0.6930210590362549.\n","Epoch 2 running, training loss is 0.6534672379493713, and training accuracy is 0.811072051525116, and step cost is 0.7014603614807129.\n","Epoch 2 running, training loss is 0.6484718322753906, and training accuracy is 0.8123709559440613, and step cost is 0.7119004726409912.\n","Epoch 2 running, training loss is 0.6434764266014099, and training accuracy is 0.8137039542198181, and step cost is 0.692401647567749.\n","Epoch 2 running, training loss is 0.6389750242233276, and training accuracy is 0.8149585723876953, and step cost is 0.6925399303436279.\n","Epoch 2 running, training loss is 0.6342794299125671, and training accuracy is 0.8161401152610779, and step cost is 0.6934928894042969.\n","Epoch 2 running, training loss is 0.6299685835838318, and training accuracy is 0.8172566294670105, and step cost is 0.6961348056793213.\n","Epoch 2 running, training loss is 0.6264544725418091, and training accuracy is 0.8182226419448853, and step cost is 0.6885294914245605.\n","Epoch 2 running, training loss is 0.6226478815078735, and training accuracy is 0.8191548585891724, and step cost is 0.6910040378570557.\n","Epoch 2 completed, training loss is 0.6200954914093018, training accuracy is 0.819868803024292, test loss is 0.5712154507637024, and test accuracy is 0.8307635188102722.\n","**********\n","Epoch 3 running, training loss is 0.6178939342498779, and training accuracy is 0.8204552531242371, and step cost is 0.7132594585418701.\n","Epoch 3 running, training loss is 0.6113348603248596, and training accuracy is 0.8223775029182434, and step cost is 0.6932499408721924.\n","Epoch 3 running, training loss is 0.6051719784736633, and training accuracy is 0.8240803480148315, and step cost is 0.6851110458374023.\n","Epoch 3 running, training loss is 0.5992097854614258, and training accuracy is 0.8258048892021179, and step cost is 0.6736631393432617.\n","Epoch 3 running, training loss is 0.5928732752799988, and training accuracy is 0.8275999426841736, and step cost is 0.6970055103302002.\n","Epoch 3 running, training loss is 0.5872011780738831, and training accuracy is 0.8291953802108765, and step cost is 0.6805567741394043.\n","Epoch 3 running, training loss is 0.5816539525985718, and training accuracy is 0.830849289894104, and step cost is 0.7056171894073486.\n","Epoch 3 running, training loss is 0.5761500597000122, and training accuracy is 0.8323660492897034, and step cost is 0.6893839836120605.\n","Epoch 3 running, training loss is 0.5711251497268677, and training accuracy is 0.8337445259094238, and step cost is 0.6996557712554932.\n","Epoch 3 running, training loss is 0.5664927363395691, and training accuracy is 0.8350485563278198, and step cost is 0.7025651931762695.\n","Epoch 3 running, training loss is 0.5614091157913208, and training accuracy is 0.8365282416343689, and step cost is 0.693716287612915.\n","Epoch 3 running, training loss is 0.5564813017845154, and training accuracy is 0.8379533290863037, and step cost is 0.6659364700317383.\n","Epoch 3 running, training loss is 0.551720917224884, and training accuracy is 0.8393471240997314, and step cost is 0.6913766860961914.\n","Epoch 3 running, training loss is 0.5471289753913879, and training accuracy is 0.8406807780265808, and step cost is 0.689509391784668.\n","Epoch 3 running, training loss is 0.54289710521698, and training accuracy is 0.8418828248977661, and step cost is 0.6897408962249756.\n","Epoch 3 running, training loss is 0.538647472858429, and training accuracy is 0.8431596159934998, and step cost is 0.6831145286560059.\n","Epoch 3 running, training loss is 0.5348895192146301, and training accuracy is 0.8442312479019165, and step cost is 0.6952428817749023.\n","Epoch 3 running, training loss is 0.530762255191803, and training accuracy is 0.845431387424469, and step cost is 0.6759788990020752.\n","Epoch 3 running, training loss is 0.5266140699386597, and training accuracy is 0.8465957045555115, and step cost is 0.6802661418914795.\n","Epoch 3 running, training loss is 0.5227400660514832, and training accuracy is 0.8476545214653015, and step cost is 0.6727108955383301.\n","Epoch 3 running, training loss is 0.5191307663917542, and training accuracy is 0.848653256893158, and step cost is 0.6685676574707031.\n","Epoch 3 running, training loss is 0.5153830647468567, and training accuracy is 0.8497216701507568, and step cost is 0.7028460502624512.\n","Epoch 3 running, training loss is 0.5118303298950195, and training accuracy is 0.8507731556892395, and step cost is 0.6722760200500488.\n","Epoch 3 running, training loss is 0.5086413025856018, and training accuracy is 0.8517064452171326, and step cost is 0.7203609943389893.\n","Epoch 3 running, training loss is 0.505224347114563, and training accuracy is 0.8526976704597473, and step cost is 0.6975867748260498.\n","Epoch 3 completed, training loss is 0.5051463842391968, training accuracy is 0.8527180552482605, test loss is 0.5783399343490601, and test accuracy is 0.8331810235977173.\n","**********\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MGfdDPRigKDR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"e5a5ac1e-ac1a-4b34-c242-8974b0519c61","executionInfo":{"status":"ok","timestamp":1582460179122,"user_tz":-480,"elapsed":116471,"user":{"displayName":"Chris Chen","photoUrl":"","userId":"15295307384944031263"}}},"source":["c_1, c_2 = 0, 0\n","\n","for x_1, x_2, x_3, y_1 in test_2:\n","  pred_1 = mode_1.propagating(x_1, x_2, x_3, False)\n","  comp_1 = sum(np.array(y_1)==np.argmax(pred_1, 1))\n","  c_1, c_2 = c_1+len(pred_1), c_2+comp_1\n","\n","print('Test accuracy is '+str(c_2/c_1)+'.')"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Test accuracy is 0.8345749708122533.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Eo6NLgpL-igg","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}