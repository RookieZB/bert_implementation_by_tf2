{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"text_similarity.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"toQJl6Q4xjDp","colab_type":"text"},"source":["A text similarity classification example for ELECTRA.  \n","The data is AFQMC from https://github.com/CLUEbenchmark/CLUE."]},{"cell_type":"code","metadata":{"id":"wV-pmJAuQPmG","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rBlT22miZU8c","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599670134541,"user_tz":-480,"elapsed":2331,"user":{"displayName":"Chris Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gib6pz72VKmdLMqZPhKb2UKgIAW_6HhaEfhtM5C=s64","userId":"15295307384944031263"}}},"source":["%tensorflow_version 2.x\n","\n","import os\n","import warnings\n","import time\n","import json\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import tensorflow.keras as keras\n","\n","os.chdir('./drive/My Drive/Python/Research/bert')\n","warnings.filterwarnings('ignore')\n","tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n","\n","import mymodels as mm"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"4B2HpNZ7b9N7","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599670137306,"user_tz":-480,"elapsed":1100,"user":{"displayName":"Chris Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gib6pz72VKmdLMqZPhKb2UKgIAW_6HhaEfhtM5C=s64","userId":"15295307384944031263"}}},"source":["MODEL = 'electra'\n","MODE = 'cls'\n","MAXLEN = 128\n","CATE = 2\n","DROP = 0.5\n","LRATE = 2e-5\n","BATCH = 16\n","EPOCH = 3\n","VOCAB = 'models/electra_small_ch/vocab.txt'\n","CONFIG = 'models/electra_small_ch/electra_config.json'\n","CKPT = 'models/electra_small_ch/electra_small'"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"cXuiXbNfYCuY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1599670178487,"user_tz":-480,"elapsed":5001,"user":{"displayName":"Chris Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gib6pz72VKmdLMqZPhKb2UKgIAW_6HhaEfhtM5C=s64","userId":"15295307384944031263"}},"outputId":"1939bcff-900b-45ee-f446-27e329dd7de7"},"source":["def file_loading(file):\n","  reader1 = open(file, 'r', encoding='utf-8').readlines()\n","  return [json.loads(i1.strip()) for i1 in reader1]\n","\n","\n","def data_processing(data, tokenizer, maxlen, batch, training, key):\n","  text1, seg1, mask1, label1 = [], [], [], []\n","  \n","  for i1 in data:\n","    text2, seg2, mask2 = tokenizer.encoding(i1['sentence1'], i1['sentence2'], maxlen)\n","    text1.append(text2)\n","    seg1.append(seg2)\n","    mask1.append(mask2)\n","    label1.append(int(i1[key]))\n","\n","  text1, seg1, mask1, label1 = np.array(text1), np.array(seg1), np.array(mask1), np.array(label1)\n","  data1 = tf.data.Dataset.from_tensor_slices((text1, seg1, mask1, label1))\n","  return data1.shuffle(len(text1)).batch(batch) if training else data1.batch(batch)\n","\n","\n","tokenizer_1 = mm.Tokenizer()\n","tokenizer_1.loading(VOCAB)\n","training_1 = file_loading('tasks/datasets/afqmc/train.json')\n","dev_1 = file_loading('tasks/datasets/afqmc/dev.json')\n","training_2 = data_processing(training_1, tokenizer_1, MAXLEN, BATCH, True, 'label')\n","dev_2 = data_processing(dev_1, tokenizer_1, MAXLEN, BATCH, False, 'label')\n","print(training_1[0])"],"execution_count":3,"outputs":[{"output_type":"stream","text":["{'sentence1': '蚂蚁借呗等额还款可以换成先息后本吗', 'sentence2': '借呗有先息到期还本吗', 'label': '0'}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gzXMCDSad3rV","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599670224156,"user_tz":-480,"elapsed":40195,"user":{"displayName":"Chris Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gib6pz72VKmdLMqZPhKb2UKgIAW_6HhaEfhtM5C=s64","userId":"15295307384944031263"}}},"source":["class MyModel(keras.Model):\n","  def __init__(self, model, mode, config, drop, category):\n","    super(MyModel, self).__init__()\n","    self.bert = mm.BERT(config, model, mode)\n","    self.drop = keras.layers.Dropout(drop)\n","    self.dense = keras.layers.Dense(category, activation='softmax')\n","\n","  def propagating(self, text, segment, mask, training):\n","    x1 = self.bert.propagating(text, segment, mask, training)\n","    return self.dense(self.drop(x1, training=training))\n","\n","\n","model_1 = MyModel(MODEL, MODE, CONFIG, DROP, CATE)\n","model_1.bert.loading(CKPT)\n","function_1 = keras.losses.SparseCategoricalCrossentropy()\n","optimizer_1 = mm.AdamWV2(EPOCH*(int(len(training_1)/BATCH)+1), LRATE)\n","\n","loss_1 = tf.keras.metrics.Mean(name='training_loss')\n","acc_1 = tf.keras.metrics.SparseCategoricalAccuracy(name='training_accuracy')\n","acc_2 = tf.keras.metrics.SparseCategoricalAccuracy(name='dev_accuracy')"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"RxHmRINF9R2x","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":370},"executionInfo":{"status":"ok","timestamp":1599670708828,"user_tz":-480,"elapsed":480990,"user":{"displayName":"Chris Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gib6pz72VKmdLMqZPhKb2UKgIAW_6HhaEfhtM5C=s64","userId":"15295307384944031263"}},"outputId":"8755c0be-fca9-47df-d454-9dec1eddb87b"},"source":["@tf.function\n","def step_training(text, segment, mask, y):\n","  with tf.GradientTape() as tape_1:\n","    pred_1 = model_1.propagating(text, segment, mask, True)\n","    value_1 = function_1(y, pred_1)\n","\n","  grad_1 = tape_1.gradient(value_1, model_1.trainable_variables)\n","  grad_1, _ = tf.clip_by_global_norm(grad_1, 1.0)\n","  optimizer_1.apply_gradients(zip(grad_1, model_1.trainable_variables))\n","  loss_1(value_1)\n","  acc_1(y, pred_1)\n","\n","\n","@tf.function\n","def step_evaluating(text, segment, mask, y):\n","  pred_1 = model_1.propagating(text, segment, mask, False)\n","  acc_2(y, pred_1)\n","\n","\n","temp_1 = 'Training loss is {:.4f}, accuracy is {:.4f}.'\n","temp_2 = 'Dev accuracy is {:.4f}, and epoch cost is {:.4f}.'\n","count_1 = 0\n","\n","for e_1 in range(EPOCH):\n","  print('Epoch {} running.'.format(e_1+1))\n","  time_0 = time.time()\n","\n","  for x_1, x_2, x_3, y_1 in training_2:\n","    time_1, count_1 = time.time(), count_1+1\n","    step_training(x_1, x_2, x_3, y_1)\n","\n","    if count_1 % 500 == 0:\n","      print(temp_1.format(float(loss_1.result()), float(acc_1.result())))\n","\n","  for x_1, x_2, x_3, y_1 in dev_2:\n","    step_evaluating(x_1, x_2, x_3, y_1)\n","\n","  print(temp_2.format(float(acc_2.result()), time.time()-time_0))\n","  print('**********')\n","  acc_1.reset_states()\n","  acc_2.reset_states()"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Epoch 1 running.\n","Training loss is 0.8222, accuracy is 0.5970.\n","Training loss is 0.7478, accuracy is 0.6211.\n","Training loss is 0.7083, accuracy is 0.6389.\n","Training loss is 0.6856, accuracy is 0.6458.\n","Dev accuracy is 0.6872, and epoch cost is 171.9196.\n","**********\n","Epoch 2 running.\n","Training loss is 0.6642, accuracy is 0.6880.\n","Training loss is 0.6496, accuracy is 0.6844.\n","Training loss is 0.6377, accuracy is 0.6869.\n","Training loss is 0.6276, accuracy is 0.6879.\n","Dev accuracy is 0.7004, and epoch cost is 153.7921.\n","**********\n","Epoch 3 running.\n","Training loss is 0.6206, accuracy is 0.6971.\n","Training loss is 0.6129, accuracy is 0.6982.\n","Training loss is 0.6056, accuracy is 0.7043.\n","Training loss is 0.5994, accuracy is 0.7065.\n","Dev accuracy is 0.7027, and epoch cost is 154.0852.\n","**********\n"],"name":"stdout"}]}]}