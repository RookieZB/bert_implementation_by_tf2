{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"text_classification.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"toQJl6Q4xjDp","colab_type":"text"},"source":["A text classification example for BERT.  \n","The data is from https://github.com/FudanNLP/nlpcc2017_news_headline_categorization."]},{"cell_type":"code","metadata":{"id":"WWnNxbk7Zokr","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rBlT22miZU8c","colab_type":"code","colab":{}},"source":["%tensorflow_version 2.x\n","\n","import os\n","import warnings\n","import time\n","import json\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import tensorflow.keras as keras\n","from sklearn import preprocessing\n","\n","os.chdir('./drive/My Drive/Python/Research/bert')\n","warnings.filterwarnings('ignore')\n","\n","import mymodels as mm"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NbYyoo5qaVGU","colab_type":"code","colab":{}},"source":["MODEL = 'bert'\n","MODE = 'cls'\n","MAXLEN = 40\n","CATE = 18\n","DROP = 0.5\n","DIM = 128\n","LRATE = 5e-5\n","BATCH = 64\n","EPOCH = 3\n","VOCAB = 'models/bert_base_ch/vocab.txt'\n","CONFIG = 'models/bert_base_ch/bert_config.json'\n","CKPT = 'models/bert_base_ch/bert_model.ckpt'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ik9wS_1LPBlC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":118},"executionInfo":{"status":"ok","timestamp":1596284792877,"user_tz":-480,"elapsed":1103,"user":{"displayName":"Chris Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gib6pz72VKmdLMqZPhKb2UKgIAW_6HhaEfhtM5C=s64","userId":"15295307384944031263"}},"outputId":"c24362a2-e0a9-4bac-a565-e8d7e435c1e9"},"source":["trai_1 = pd.read_table('tasks/datasets/nlpcc_2017_news/train.txt', names=['label', 'text'])\n","deve_1 = pd.read_table('tasks/datasets/nlpcc_2017_news/dev.txt', names=['label', 'text'])\n","test_1 = pd.read_table('tasks/datasets/nlpcc_2017_news/test.txt', names=['label', 'text'])\n","\n","labe_1 = preprocessing.LabelEncoder()\n","trai_1['label'] = labe_1.fit_transform(trai_1['label'])\n","deve_1['label'] = labe_1.transform(deve_1['label'])\n","test_1['label'] = labe_1.transform(test_1['label'])\n","\n","print(trai_1.head())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["   label                                               text\n","0      3      台 媒 预 测 周 冬 雨 金 马 奖 封 后 ， 大 气 的 倪 妮 却 佳 作 难 出\n","1      7  农 村 就 是 好 ， 能 吃 到 纯 天 然 无 添 加 的 野 生 蜂 蜜 ， 营 养 ...\n","2      5        1 4 款 知 性 美 装 ， 时 尚 惊 艳 搁 浅 的 阳 光 轻 熟 的 优 雅\n","3      9              火 焰 喷 射 器 1 0 0 0 度 火 焰 烧 死 鬼 子 4 连 拍\n","4     12                            1 8 岁 青 年 砍 死 8 8 岁 老 兵\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cXuiXbNfYCuY","colab_type":"code","colab":{}},"source":["def data_processing(data, tokenizer, maxlen, batch, training):\n","  text1, type1, mask1, labe1 = [], [], [], []\n","  \n","  for i in range(len(data)):\n","    text2, type2, mask2 = tokenizer.encoding(data['text'][i], None, maxlen)\n","    labe2 = data['label'][i]\n","    text1.append(text2)\n","    type1.append(type2)\n","    mask1.append(mask2)\n","    labe1.append(labe2)\n","    \n","  text1, type1, mask1 = np.array(text1), np.array(type1), np.array(mask1)\n","  data1 = tf.data.Dataset.from_tensor_slices((text1, type1, mask1, np.array(labe1)))\n","  return data1.shuffle(len(text1)).batch(batch) if training else data1.batch(batch)\n","\n","\n","toke_1 = mm.Tokenizer()\n","toke_1.loading(VOCAB)\n","trai_2 = data_processing(trai_1, toke_1, MAXLEN, BATCH, True)\n","deve_2 = data_processing(deve_1, toke_1, MAXLEN, BATCH, False)\n","test_2 = data_processing(test_1, toke_1, MAXLEN, BATCH, False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RZj2lAHIa05b","colab_type":"code","colab":{}},"source":["class MyModel(keras.Model):\n","  def __init__(self, model, mode, config, drop, dim, category):\n","    super(MyModel, self).__init__()\n","    self.bert = mm.BERT(config, model, mode)\n","    self.drop = keras.layers.Dropout(drop)\n","    self.dense1 = keras.layers.Dense(dim, activation='relu')\n","    self.dense2 = keras.layers.Dense(category, activation='softmax')\n","\n","  def propagating(self, text, segment, mask, training):\n","    x1 = self.bert.propagating(text, segment, mask, training)\n","    x1 = self.drop(x1, training=training)\n","    return self.dense2(self.dense1(x1))\n","\n","\n","mode_1 = MyModel(MODEL, MODE, CONFIG, DROP, DIM, CATE)\n","mode_1.bert.loading(CKPT)\n","step_1 = EPOCH*(int(len(trai_1)/BATCH)+1)\n","loss_0 = keras.losses.SparseCategoricalCrossentropy()\n","opti_1 = mm.AdamWV2(step_1, LRATE)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3-kZtSX8ecC4","colab_type":"code","colab":{}},"source":["loss_1 = tf.keras.metrics.Mean(name='training_loss')\n","accu_1 = tf.keras.metrics.SparseCategoricalAccuracy(name='training_accuracy')\n","loss_2 = tf.keras.metrics.Mean(name='dev_loss')\n","accu_2 = tf.keras.metrics.SparseCategoricalAccuracy(name='dev_accuracy')\n","\n","\n","@tf.function\n","def step_training(text, segment, mask, y):\n","  with tf.GradientTape() as tape_1:\n","    pred_1 = mode_1.propagating(text, segment, mask, True)\n","    valu_1 = loss_0(y, pred_1)\n","\n","  grad_1 = tape_1.gradient(valu_1, mode_1.trainable_variables)\n","  grad_1, _ = tf.clip_by_global_norm(grad_1, 1.0)\n","  opti_1.apply_gradients(zip(grad_1, mode_1.trainable_variables))\n","  loss_1(valu_1)\n","  accu_1(y, pred_1)\n","\n","\n","@tf.function\n","def step_evaluating(text, segment, mask, y):\n","  pred_1 = mode_1.propagating(text, segment, mask, False)\n","  valu_1 = loss_0(y, pred_1)\n","  loss_2(valu_1)\n","  accu_2(y, pred_1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a1E2v8k9ecAO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":403},"executionInfo":{"status":"ok","timestamp":1596287759749,"user_tz":-480,"elapsed":2782728,"user":{"displayName":"Chris Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gib6pz72VKmdLMqZPhKb2UKgIAW_6HhaEfhtM5C=s64","userId":"15295307384944031263"}},"outputId":"e41f110e-427b-42c8-a1f6-1385a5c36808"},"source":["temp_1 = 'Training loss is {}, accuracy is {}, and step cost is {}.'\n","temp_2 = 'Dev accuracy is {}, and epoch cost is {}.'\n","coun_1 = 0\n","\n","for e_1 in range(EPOCH):\n","  print('Epoch {} running.'.format(e_1+1))\n","  time_0 = time.time()\n","\n","  for x_1, x_2, x_3, y_1 in trai_2:\n","    time_1, coun_1 = time.time(), coun_1+1\n","    step_training(x_1, x_2, x_3, y_1)\n","\n","    if coun_1 % 500 == 0:\n","      o_1, o_2 = round(float(loss_1.result()), 4), round(float(accu_1.result()), 4)\n","      print(temp_1.format(o_1, o_2, round(time.time()-time_1, 4)))\n","\n","  for x_1, x_2, x_3, y_1 in deve_2:\n","    step_evaluating(x_1, x_2, x_3, y_1)\n","  \n","  print(temp_2.format(round(float(accu_2.result()), 4), round(time.time()-time_0, 4)))\n","  print('**********')\n","  accu_1.reset_states()\n","  accu_2.reset_states()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1 running.\n","Training loss is 1.5628, accuracy is 0.578, and step cost is 0.35.\n","Training loss is 1.1704, accuracy is 0.6805, and step cost is 0.3596.\n","Training loss is 1.0157, accuracy is 0.7196, and step cost is 0.3738.\n","Training loss is 0.929, accuracy is 0.741, and step cost is 0.3566.\n","Dev accuracy is 0.8234, and epoch cost is 936.8971.\n","**********\n","Epoch 2 running.\n","Training loss is 0.8692, accuracy is 0.8494, and step cost is 0.3585.\n","Training loss is 0.8073, accuracy is 0.8546, and step cost is 0.3557.\n","Training loss is 0.7605, accuracy is 0.8558, and step cost is 0.3532.\n","Training loss is 0.7252, accuracy is 0.8567, and step cost is 0.3568.\n","Training loss is 0.698, accuracy is 0.8571, and step cost is 0.3542.\n","Dev accuracy is 0.8378, and epoch cost is 922.7776.\n","**********\n","Epoch 3 running.\n","Training loss is 0.6703, accuracy is 0.9068, and step cost is 0.3572.\n","Training loss is 0.6374, accuracy is 0.9072, and step cost is 0.3549.\n","Training loss is 0.6096, accuracy is 0.9089, and step cost is 0.3528.\n","Training loss is 0.5869, accuracy is 0.9083, and step cost is 0.3557.\n","Training loss is 0.567, accuracy is 0.9088, and step cost is 0.3558.\n","Dev accuracy is 0.841, and epoch cost is 922.1643.\n","**********\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tD4AgDwPrQ7E","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596287830041,"user_tz":-480,"elapsed":63088,"user":{"displayName":"Chris Chen","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gib6pz72VKmdLMqZPhKb2UKgIAW_6HhaEfhtM5C=s64","userId":"15295307384944031263"}},"outputId":"4d04098d-9928-4813-d133-b338e8f519dd"},"source":["c_1, c_2 = 0, 0\n","\n","for x_1, x_2, x_3, y_1 in test_2:\n","  pred_1 = mode_1.propagating(x_1, x_2, x_3, False)\n","  comp_1 = sum(np.array(y_1)==np.argmax(pred_1, 1))\n","  c_1, c_2 = c_1+len(pred_1), c_2+comp_1\n","\n","print('Test accuracy is '+str(round(float(c_2/c_1), 4))+'.')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Test accuracy is 0.8428.\n"],"name":"stdout"}]}]}